{
    "docs": [
        {
            "location": "/", 
            "text": "BEAST.jl documentation\n\n\nBEAST provides a number of types modelling concepts and a number of algorithms for the efficient and simple implementation of boundary and finite element solvers. It provides full implementations of these concepts for the LU based solution of boundary integral equations for the Maxwell and Helmholtz systems.\n\n\nBecause Julia only compiles code at execution time, users of this library can hook into the code provided in this package at any level. In the extreme case it suffices to provide overwrites of the \nassemble\n functions. In that case, only the LU solution will be performed by the code here.\n\n\nAt the other end it suffices that users only supply integration kernels that act on the element-element interaction level. This package will manage all required steps for matrix assembly.\n\n\nFor the Helmholtz 2D and Maxwell 3D systems, complete implementations are supplied. These models will be discussed in detail to give a more concrete idea of the APIs provides and how to extend them.\n\n\nCentral to the solution of boundary integral equations is the assembly of the system matrix. The system matrix is fully determined by specifying a kernel G, a set of trial functions, and a set of test functions.\n\n\n\n\nBasis\n\n\nSets of both trial and testing functions are implemented by models following the basis concept. The term basis is somewhat misleading as it is nowhere required nor enforced that these functions are linearly independent. Models implementing the Basis concept need to comply to the following semantics.\n\n\n\n\nnumfunctions(basis)\n: number of functions in the Basis.\n\n\ncoordtype(basis)\n: type of (the components of) the values taken on by the functions in the Basis.\n\n\nscalartype(d)\n: the scalar field underlying the vector space the basis functions take value in.\n\n\nrefspace(basis)\n: returns the ReferenceSpace of local shape functions on which the Basis is built.\n\n\nassemblydata(basis)\n: \nassemblydata\n returns an iterable collection \nelements\n of geometric elements and a look table \nad\n for use in assembly of interaction matrices. In particular, for an index \nelement_idx\n into \nelements\n and an index \nlocal_shape_idx\n in basis of local shape functions \nrefspace(basis)\n, \nad[element_idx, local_shape_idx]\n returns the iterable collection of \n(global_idx, weight)\n tuples such that the local shape function at \nlocal_shape_idx\n defined on the element at \nelement_idx\n contributes to the basis function at \nglobal_idx\n with a weight of \nweight\n.\n\n\ngeometry(basis)\n: returns an iterable collection of Elements. The order in which these Elements are encountered corresponds to the indices used in the assembly data structure.\n\n\n\n\n\n\nReference Space\n\n\nThe \nreference space\n concept defines an API for working with spaces of local shape functions. The main role of objects implementing this concept is to allow specialization of the functions that depend on the precise reference space used.\n\n\nThe functions that depend on the type and value of arguments modeling \nreference space\n are:\n\n\n\n\nnumfunctions(refspace)\n: returns the number of shape functions on each element.\n\n\n\n\n\n\nKernel\n\n\nA kernel is a fairly simple concept that mainly exists as part of the definition of a Discrete Operator. A kernel should obey the following semantics:\n\n\nIn many function definitions the kernel object is referenced by \noperator\n or something similar. This is a misleading name as an operator definition should always be accompanied by the domain and range space.\n\n\n\n\nDiscrete Operator\n\n\nInformally speaking, a Discrete Operator is a concept that allows for the computation of an interaction matrix. It is a kernel together with a test and trial basis. A Discrete Operator can be passed to \nassemble\n and friends to compute its matrix representation.\n\n\nA discrete operator is a triple \n(kernel, test_basis, trial_basis)\n, where \nkernel\n is a Kernel, and \ntest_basis\n and \ntrial_basis\n are Bases. In addition, the following expressions should be implemented and behave according to the correct semantics:\n\n\n\n\nquaddata(operator,test_refspace,trial_refspace,test_elements,trial_elements)\n: create the data required for the computation of element-element interactions during assembly of discrete operator matrices.\n\n\nquadrule(operator,test_refspace,trial_refspace,p,test_element,q_trial_element,qd)\n: returns an integration strategy object that will be passed to \nmomintegrals!\n to select an integration strategy. This rule can depend on the test/trial reference spaces and interacting elements. The indices \np\n and \nq\n refer to the position of the interacting elements in the enumeration defined by \ngeometry(basis)\n and allow for fast retrieval of any element specific data stored in the quadrature data object \nqd\n.\n\n\nmomintegrals!(operator,test_refspace,trial_refspace,test_element,trial_element,zlocal,qr)\n: this function computes the local interaction matrix between the set of local test and trial shape functions and a specific pair of elements. The target matrix \nzlocal\n is provided as an argument to minimise memory allocations over subsequent calls. \nqr\n is an object returned by \nquadrule\n and contains all static and dynamic data defining the integration strategy used.\n\n\n\n\nIn the context of fast methods such as the Fast Multipole Method other algorithms on Discrete Operators will typically be defined to compute matrix vector products. These algorithms do not explicitly compute and store the interaction matrix (this would lead to unacceptable computational and memory complexity).\n\n\n#\n\n\nBEAST.elements\n \n \nFunction\n.\n\n\nelements(geo)\n\n\nCreate an iterable collection of the elements stored in \ngeo\n. The order in which this collection produces the elements determines the index used for lookup in the data structures returned by \nassemblydata\n and \nquaddata\n.\n\n\nsource\n\n\n#\n\n\nBEAST.numfunctions\n \n \nFunction\n.\n\n\nnumfunctions(r)\n\n\n\n\nReturn the number of functions in a \nSpace\n or \nRefSpace\n.\n\n\nsource\n\n\n#\n\n\nCompScienceMeshes.coordtype\n \n \nFunction\n.\n\n\ncoordtype(mesh)\n\n\n\n\nReturns \neltype(vertextype(mesh))\n\n\nsource\n\n\ncoordtype(simplex)\n\n\n\n\nReturn coordinate type used by simplex.\n\n\nsource\n\n\n#\n\n\nBEAST.scalartype\n \n \nFunction\n.\n\n\nscalartype(x)\n\n\n\n\nThe scalar field over which the values of a global or local basis function, or an operator are defined. This should always be a scalar type, even if the basis or operator takes on values in a vector or tensor space. This data type is used to determine the \neltype\n of assembled discrete operators.\n\n\nsource\n\n\n#\n\n\nBEAST.assemblydata\n \n \nFunction\n.\n\n\nassemblydata(basis)\n\n\n\n\nGiven a Basis this function returns a data structure containing the information required for matrix assemble. More precise the following expressions are valid for the returned object \nad\n:\n\n\nad[c,r,i].globalindex\nad[c,r,i].coefficient\n\n\n\n\nHere, \nc\n and \nr\n are indices in the iterable set of geometric elements and the set of local shape functions on each element. \ni\n ranges from 1 to the maximum number of basis functions local shape function \nr\n on element \nr\n contributes to.\n\n\nFor a triplet \n(c,r,i)\n, \nglobalindex\n is the index in the Basis of the \ni\n-th basis function that has a contribution from local shape function \nr\n on element \nr\n. \ncoefficient\n is the coefficient of that contribution in the linear combination defining that basis function in terms of local shape function.\n\n\nNote\n: the indices \nc\n correspond to the position of the corresponding element whilst iterating over \ngeometry(basis)\n.\n\n\nsource\n\n\n#\n\n\nBEAST.geometry\n \n \nFunction\n.\n\n\ngeometry(basis)\n\n\n\n\nReturns an iterable collection of geometric elements on which the functions in \nbasis\n are defined. The order the elements are encountered needs correspond to the element indices used in the data structure returned by \nassemblydata\n.\n\n\nsource\n\n\n#\n\n\nBEAST.refspace\n \n \nFunction\n.\n\n\nrefspace(basis)\n\n\n\n\nReturns the ReferenceSpace of local shape functions on which the basis is built.\n\n\nsource\n\n\n#\n\n\nBEAST.quaddata\n \n \nFunction\n.\n\n\nquaddata(operator, test_refspace, trial_refspace, test_elements, trial_elements)\n\n\n\n\nReturns an object cashing data required for the computation of boundary element interactions. It is up to the client programmer to decide what (if any) data is cached. For double numberical quadrature, storing the integration points for example can significantly speed up matrix assembly.\n\n\n\n\noperator\n is an integration kernel.\n\n\ntest_refspace\n and \ntrial_refspace\n are reference space objects. \nquadata\n\n\n\n\nis typically overloaded on the type of these local spaces of shape functions. (See the implementation in \nmaxwell.jl\n for an example).\n\n\n\n\ntest_elements\n and \ntrial_elements\n are iterable collections of the geometric\n\n\n\n\nelements on which the finite element space are defined. These are provided to allow computation of the actual integrations points - as opposed to only their coordinates.\n\n\nsource\n\n\n#\n\n\nBEAST.quadrule\n \n \nFunction\n.\n\n\nquadrule(operator,test_refspace,trial_refspace,p,test_element,q_trial_element, qd)\n\n\n\n\nReturns an object that contains all the dynamic (runtime) information that defines the integration strategy that will be used by \nmomintegrals!\n to compute the interactions between the local test/trial functions defined on the specified geometric elements. The indices \np\n and \nq\n refer to the position of the test and trial elements as encountered during iteration over the output of \ngeometry\n.\n\n\nThe last argument \nqd\n provides access to all precomputed data required for quadrature. For example it might be desirable to precompute all the quadrature points for all possible numerical quadrature schemes that can potentially be required during matrix assembly. This makes sense, since the number of point is order N (where N is the number of faces) but these points will appear in N^2 computations. Precomputation requires some extra memory but can save a lot on computation time.\n\n\nsource\n\n\n#\n\n\nBEAST.momintegrals!\n \n \nFunction\n.\n\n\nregularcellcellinteractions!(biop, tshs, bshs, tcell, bcell, interactions, strat)\n\n\n\n\nFunction for the computation of moment integrals using simple double quadrature.\n\n\nsource", 
            "title": "Home"
        }, 
        {
            "location": "/#beastjl-documentation", 
            "text": "BEAST provides a number of types modelling concepts and a number of algorithms for the efficient and simple implementation of boundary and finite element solvers. It provides full implementations of these concepts for the LU based solution of boundary integral equations for the Maxwell and Helmholtz systems.  Because Julia only compiles code at execution time, users of this library can hook into the code provided in this package at any level. In the extreme case it suffices to provide overwrites of the  assemble  functions. In that case, only the LU solution will be performed by the code here.  At the other end it suffices that users only supply integration kernels that act on the element-element interaction level. This package will manage all required steps for matrix assembly.  For the Helmholtz 2D and Maxwell 3D systems, complete implementations are supplied. These models will be discussed in detail to give a more concrete idea of the APIs provides and how to extend them.  Central to the solution of boundary integral equations is the assembly of the system matrix. The system matrix is fully determined by specifying a kernel G, a set of trial functions, and a set of test functions.", 
            "title": "BEAST.jl documentation"
        }, 
        {
            "location": "/#basis", 
            "text": "Sets of both trial and testing functions are implemented by models following the basis concept. The term basis is somewhat misleading as it is nowhere required nor enforced that these functions are linearly independent. Models implementing the Basis concept need to comply to the following semantics.   numfunctions(basis) : number of functions in the Basis.  coordtype(basis) : type of (the components of) the values taken on by the functions in the Basis.  scalartype(d) : the scalar field underlying the vector space the basis functions take value in.  refspace(basis) : returns the ReferenceSpace of local shape functions on which the Basis is built.  assemblydata(basis) :  assemblydata  returns an iterable collection  elements  of geometric elements and a look table  ad  for use in assembly of interaction matrices. In particular, for an index  element_idx  into  elements  and an index  local_shape_idx  in basis of local shape functions  refspace(basis) ,  ad[element_idx, local_shape_idx]  returns the iterable collection of  (global_idx, weight)  tuples such that the local shape function at  local_shape_idx  defined on the element at  element_idx  contributes to the basis function at  global_idx  with a weight of  weight .  geometry(basis) : returns an iterable collection of Elements. The order in which these Elements are encountered corresponds to the indices used in the assembly data structure.", 
            "title": "Basis"
        }, 
        {
            "location": "/#reference-space", 
            "text": "The  reference space  concept defines an API for working with spaces of local shape functions. The main role of objects implementing this concept is to allow specialization of the functions that depend on the precise reference space used.  The functions that depend on the type and value of arguments modeling  reference space  are:   numfunctions(refspace) : returns the number of shape functions on each element.", 
            "title": "Reference Space"
        }, 
        {
            "location": "/#kernel", 
            "text": "A kernel is a fairly simple concept that mainly exists as part of the definition of a Discrete Operator. A kernel should obey the following semantics:  In many function definitions the kernel object is referenced by  operator  or something similar. This is a misleading name as an operator definition should always be accompanied by the domain and range space.", 
            "title": "Kernel"
        }, 
        {
            "location": "/#discrete-operator", 
            "text": "Informally speaking, a Discrete Operator is a concept that allows for the computation of an interaction matrix. It is a kernel together with a test and trial basis. A Discrete Operator can be passed to  assemble  and friends to compute its matrix representation.  A discrete operator is a triple  (kernel, test_basis, trial_basis) , where  kernel  is a Kernel, and  test_basis  and  trial_basis  are Bases. In addition, the following expressions should be implemented and behave according to the correct semantics:   quaddata(operator,test_refspace,trial_refspace,test_elements,trial_elements) : create the data required for the computation of element-element interactions during assembly of discrete operator matrices.  quadrule(operator,test_refspace,trial_refspace,p,test_element,q_trial_element,qd) : returns an integration strategy object that will be passed to  momintegrals!  to select an integration strategy. This rule can depend on the test/trial reference spaces and interacting elements. The indices  p  and  q  refer to the position of the interacting elements in the enumeration defined by  geometry(basis)  and allow for fast retrieval of any element specific data stored in the quadrature data object  qd .  momintegrals!(operator,test_refspace,trial_refspace,test_element,trial_element,zlocal,qr) : this function computes the local interaction matrix between the set of local test and trial shape functions and a specific pair of elements. The target matrix  zlocal  is provided as an argument to minimise memory allocations over subsequent calls.  qr  is an object returned by  quadrule  and contains all static and dynamic data defining the integration strategy used.   In the context of fast methods such as the Fast Multipole Method other algorithms on Discrete Operators will typically be defined to compute matrix vector products. These algorithms do not explicitly compute and store the interaction matrix (this would lead to unacceptable computational and memory complexity).  #  BEAST.elements     Function .  elements(geo)  Create an iterable collection of the elements stored in  geo . The order in which this collection produces the elements determines the index used for lookup in the data structures returned by  assemblydata  and  quaddata .  source  #  BEAST.numfunctions     Function .  numfunctions(r)  Return the number of functions in a  Space  or  RefSpace .  source  #  CompScienceMeshes.coordtype     Function .  coordtype(mesh)  Returns  eltype(vertextype(mesh))  source  coordtype(simplex)  Return coordinate type used by simplex.  source  #  BEAST.scalartype     Function .  scalartype(x)  The scalar field over which the values of a global or local basis function, or an operator are defined. This should always be a scalar type, even if the basis or operator takes on values in a vector or tensor space. This data type is used to determine the  eltype  of assembled discrete operators.  source  #  BEAST.assemblydata     Function .  assemblydata(basis)  Given a Basis this function returns a data structure containing the information required for matrix assemble. More precise the following expressions are valid for the returned object  ad :  ad[c,r,i].globalindex\nad[c,r,i].coefficient  Here,  c  and  r  are indices in the iterable set of geometric elements and the set of local shape functions on each element.  i  ranges from 1 to the maximum number of basis functions local shape function  r  on element  r  contributes to.  For a triplet  (c,r,i) ,  globalindex  is the index in the Basis of the  i -th basis function that has a contribution from local shape function  r  on element  r .  coefficient  is the coefficient of that contribution in the linear combination defining that basis function in terms of local shape function.  Note : the indices  c  correspond to the position of the corresponding element whilst iterating over  geometry(basis) .  source  #  BEAST.geometry     Function .  geometry(basis)  Returns an iterable collection of geometric elements on which the functions in  basis  are defined. The order the elements are encountered needs correspond to the element indices used in the data structure returned by  assemblydata .  source  #  BEAST.refspace     Function .  refspace(basis)  Returns the ReferenceSpace of local shape functions on which the basis is built.  source  #  BEAST.quaddata     Function .  quaddata(operator, test_refspace, trial_refspace, test_elements, trial_elements)  Returns an object cashing data required for the computation of boundary element interactions. It is up to the client programmer to decide what (if any) data is cached. For double numberical quadrature, storing the integration points for example can significantly speed up matrix assembly.   operator  is an integration kernel.  test_refspace  and  trial_refspace  are reference space objects.  quadata   is typically overloaded on the type of these local spaces of shape functions. (See the implementation in  maxwell.jl  for an example).   test_elements  and  trial_elements  are iterable collections of the geometric   elements on which the finite element space are defined. These are provided to allow computation of the actual integrations points - as opposed to only their coordinates.  source  #  BEAST.quadrule     Function .  quadrule(operator,test_refspace,trial_refspace,p,test_element,q_trial_element, qd)  Returns an object that contains all the dynamic (runtime) information that defines the integration strategy that will be used by  momintegrals!  to compute the interactions between the local test/trial functions defined on the specified geometric elements. The indices  p  and  q  refer to the position of the test and trial elements as encountered during iteration over the output of  geometry .  The last argument  qd  provides access to all precomputed data required for quadrature. For example it might be desirable to precompute all the quadrature points for all possible numerical quadrature schemes that can potentially be required during matrix assembly. This makes sense, since the number of point is order N (where N is the number of faces) but these points will appear in N^2 computations. Precomputation requires some extra memory but can save a lot on computation time.  source  #  BEAST.momintegrals!     Function .  regularcellcellinteractions!(biop, tshs, bshs, tcell, bcell, interactions, strat)  Function for the computation of moment integrals using simple double quadrature.  source", 
            "title": "Discrete Operator"
        }, 
        {
            "location": "/tutorial/", 
            "text": "Tutorial\n\n\n\n\n\n\\newcommand{\\vt}[1]{\\boldsymbol{#1}}\n\\newcommand{\\uv}[1]{\\hat{\\boldsymbol{#1}}}\n\\newcommand{\\arr}[1]{\\mathsf{#1}}\n\\newcommand{\\mat}[1]{\\boldsymbol{\\mathsf{#1}}}\n\n\n\n\n\nIn this tutorial we will go through the steps required for the formulation and the solution of the scattering of a time harmonic electromagnetic wave by a rectangular plate by means of the solution of the electric field integral equation.\n\n\n\n\nBuilding the geometry\n\n\nThe sibling package \nCompScienceMeshes\n provides data structures and algorithms for working with simplical meshes in computational science. We will use it to create the geometry:\n\n\nusing CompScienceMeshes, BEAST\no, x, y, z = euclidianbasis(3)\n\nh = 0.2\n\u0393 = meshrectangle(1.0, 1.0, h)\n@show numvertices(\u0393)\n@show numcells(\u0393)\n\n\n\n\nnumvertices(\u0393) = 36\nnumcells(\u0393) = 50\n\n\n\n\nNext, we create the finite element space of Raviart-Thomas aka Rao-Wilton-Glisson functions subordinate to the triangulation \n\u0393\n constructed above:\n\n\nX = raviartthomas(\u0393)\n\n\n\n\nThe scattering problem is defined by specifying the single layer operator and the functional acting as excitation. Here, the plate is illuminated by a plane wave. The actual excitation is the tangential trace of this electric field. This trace be constructed easily by using the symbolic normal vector field \nn\n defined as part of the \nBEAST\n package.\n\n\n\u03ba = 1.0\nE = Maxwell3D.planewave(direction=z\u0302, polarization=x\u0302, wavenumber=\u03ba)\ne = (n \u00d7 E) \u00d7 n\n\n\n\n\nThe single layer potential is also predefined by the \nBEAST\n package:\n\n\nt = Maxwell3D.singlelayer(wavenumber=\u03ba)\n\n\n\n\nIt corresponds to the bilinear form\n\n\n\n\n\nt(\\vt{k},\\vt{j}) = \\frac{1}{ik} \\int_{\\Gamma} \\int_{\\Gamma'} \\nabla \\cdot \\vt{k}(x) \\nabla \\cdot \\vt{j}(y) \\frac{e^{-ik|x-y|}}{4\\pi|x-y|} dy dx - ik \\int_{\\Gamma} \\int_{\\Gamma'} \\vt{k}(x) \\cdot \\vt{j}(y) \\frac{e^{-ik|x-y|}}{4\\pi|x-y|} dy dx\n\n\n\n\n\nUsing the \nLinearForms\n package, which implements a simple form compiler for Julia (\n@varform\n), the EFIE can be defined and discretised by\n\n\n@hilbertspace j\n@hilbertspace k\nefie = @discretise t[k,j]==e[k]  j\u2208X k\u2208X\n\n\n\n\nSolving and computing the values of the induced current in the centers of the triangles of the mesh is now straightforward:\n\n\nu = solve(efie)\nfcr, geo = facecurrents(u,X)\n\n\n\n\nThe resulting current distribution can be visualised by e.g. Matlab, Paraview, Plotly,...", 
            "title": "Tutorial"
        }, 
        {
            "location": "/tutorial/#tutorial", 
            "text": "\\newcommand{\\vt}[1]{\\boldsymbol{#1}}\n\\newcommand{\\uv}[1]{\\hat{\\boldsymbol{#1}}}\n\\newcommand{\\arr}[1]{\\mathsf{#1}}\n\\newcommand{\\mat}[1]{\\boldsymbol{\\mathsf{#1}}}   In this tutorial we will go through the steps required for the formulation and the solution of the scattering of a time harmonic electromagnetic wave by a rectangular plate by means of the solution of the electric field integral equation.", 
            "title": "Tutorial"
        }, 
        {
            "location": "/tutorial/#building-the-geometry", 
            "text": "The sibling package  CompScienceMeshes  provides data structures and algorithms for working with simplical meshes in computational science. We will use it to create the geometry:  using CompScienceMeshes, BEAST\no, x, y, z = euclidianbasis(3)\n\nh = 0.2\n\u0393 = meshrectangle(1.0, 1.0, h)\n@show numvertices(\u0393)\n@show numcells(\u0393)  numvertices(\u0393) = 36\nnumcells(\u0393) = 50  Next, we create the finite element space of Raviart-Thomas aka Rao-Wilton-Glisson functions subordinate to the triangulation  \u0393  constructed above:  X = raviartthomas(\u0393)  The scattering problem is defined by specifying the single layer operator and the functional acting as excitation. Here, the plate is illuminated by a plane wave. The actual excitation is the tangential trace of this electric field. This trace be constructed easily by using the symbolic normal vector field  n  defined as part of the  BEAST  package.  \u03ba = 1.0\nE = Maxwell3D.planewave(direction=z\u0302, polarization=x\u0302, wavenumber=\u03ba)\ne = (n \u00d7 E) \u00d7 n  The single layer potential is also predefined by the  BEAST  package:  t = Maxwell3D.singlelayer(wavenumber=\u03ba)  It corresponds to the bilinear form   \nt(\\vt{k},\\vt{j}) = \\frac{1}{ik} \\int_{\\Gamma} \\int_{\\Gamma'} \\nabla \\cdot \\vt{k}(x) \\nabla \\cdot \\vt{j}(y) \\frac{e^{-ik|x-y|}}{4\\pi|x-y|} dy dx - ik \\int_{\\Gamma} \\int_{\\Gamma'} \\vt{k}(x) \\cdot \\vt{j}(y) \\frac{e^{-ik|x-y|}}{4\\pi|x-y|} dy dx   Using the  LinearForms  package, which implements a simple form compiler for Julia ( @varform ), the EFIE can be defined and discretised by  @hilbertspace j\n@hilbertspace k\nefie = @discretise t[k,j]==e[k]  j\u2208X k\u2208X  Solving and computing the values of the induced current in the centers of the triangles of the mesh is now straightforward:  u = solve(efie)\nfcr, geo = facecurrents(u,X)  The resulting current distribution can be visualised by e.g. Matlab, Paraview, Plotly,...", 
            "title": "Building the geometry"
        }, 
        {
            "location": "/assemble/", 
            "text": "The Matrix Assemble Routine\n\n\nA lot of the design of this package derives from the need to express boundary element and finite element matrix assembly in a concise but general manner that is compatible with a wide range of linear and bilinear forms as encountered in the solution of variational problems.\n\n\nIn this section the matrix assembly routine at the center of this package will be discussed. As a case study we will go over the steps required to extend support for new kernels and new finite element spaces.\n\n\nThe matrix assemble routine is surprisingly short:\n\n\nfunction assemblechunk!(biop::IntegralOperator, tfs::Space, bfs::Space, store)\n\n    test_elements, tad = assemblydata(tfs)\n    bsis_elements, bad = assemblydata(bfs)\n\n    tshapes = refspace(tfs); num_tshapes = numfunctions(tshapes)\n    bshapes = refspace(bfs); num_bshapes = numfunctions(bshapes)\n\n    T = promote_type(scalartype(biop), scalartype(tfs), scalartype(bfs))\n    zlocal = zeros(T, num_tshapes, num_bshapes)\n\n    qd = quaddata(biop, tshapes, bshapes, test_elements, bsis_elements)\n    for (p,tcell) in enumerate(test_elements), (q,bcell) in enumerate(bsis_elements)\n\n        fill!(zlocal, 0)\n        strat = quadrule(biop, tshapes, bshapes, p, tcell, q, bcell, qd)\n        momintegrals!(biop, tshapes, bshapes, tcell, bcell, zlocal, strat)\n\n        for j in 1 : num_bshapes, i in 1 : num_tshapes\n            z = zlocal[i,j]\n            for (m,a) in tad[p,i], (n,b) in bad[q,j]\n                store(a*z*b, m, n)\nend end end end\n\n\n\n\nSupport for direct product spaces, linear combinations of kernels, non-standard storage of matrix elements, and parallel execution is provided by layers on top of this assembly routine. In this section we will focus on discussing the design and implementation of this inner building block that lies at the basis of more general functionality.\n\n\nFinite element spaces are usually stored as a collection of functions that in turn each comprise contributions from a limited number of geometric elements that make up the support of the function. In FEM and BEM matrix assembly, however, we need the \ntranposed\n information: given a geometric cell, and a local shape function, we need the ability to efficiently retrieve the list of basis functions whose definition contains the given local shape function on the given cell and the weight (aka coefficient) by which it contributes. The data structure that contains this information is referred to as the assembly data \nad\n. In particular, \nad[e,s]\n, where \ne\n is the index of a geometric cell and \ns\n is the index of a local shape function, returns an iterable collection of pairs \n(m,w)\n where \nm\n is an index into the iterable collection of basis functions making up the finite element space and \nw\n is a weight, such that shape function \ns\n on geometric element \ne\n contributes with weight \nw\n to basis function \nn\n.\n\n\ntest_elements, tad = assemblydata(tfs)\nbsis_elements, bad = assemblydata(bfs)\n\n\n\n\nOne final note on the \nassemblydata\n function: as you can see from the above snippet, the function returns, in addition to the actual assembly data, an iterable collection of geometric elements. This collection is a subset of the collection of elements making up the geometry on which the finite element space is defined. The elements returned are those that actually appear in the domain of one or more of the functions that span the finite element space. The double for loop that iterates over pairs of trial and testing functions will only visit those used elements. Elements that are part of the geometry but do not appear as part of the support of a function are skipped. This behaviour is required to guarantee scalability when using multiple threads in assembling the matrix: each thread is assigned a subset of the basis functions; visiting unused elements in all threads is harmful for the overall efficiency.\n\n\nWith this assembly data in hand, matrix assembly can be done by iterating over geometric cells, rather than over basis functions. Doing this avoids visiting a given geometric cell more than once. When computing matrices resulting from discretisation with e.g. Raviart-Thomas elements, this can speed up assembly time with a factor 9.\n\n\nThe problem of matrix assembly is now reduced to the computation of interactions between local shape functions defined on all possible pairs of geometric cells. The space of local shape functions can be retrieved by calling\n\n\ntshapes = refspace(tfs); num_tshapes = numfunctions(tshapes)\nbshapes = refspace(bfs); num_bshapes = numfunctions(bshapes)\n\n\n\n\nHere, \nnum_tshapes\n and \nnum_bshapes\n are the number of local shape functions. For example, when using Raviart-Thomas elements, the number of local shape functions equals three (one for every edge of the reference triangle).\n\n\nBased on this dimension, and based on the types used to represent numbers in the fields over which the spaces and the kernel are defined, the storage for local shape function interaction is pre-allocated:\n\n\nT = promote_type(scalartype(biop), scalartype(tfs), scalartype(bfs))\nzlocal = zeros(T, num_tshapes, num_bshapes)\n\n\n\n\nNote that the computation of the storage type ensures that high precision or complex data types are only used when required. At all times the minimal storage type is selected. Not only does this keep memory use down, it also results in faster linear algebra computations such as matrix-vector multiplication.\n\n\nBefore entering the double for loop that is responsible for the enumeration of all pairs of geometric cells (a trial cell pairs with a test cell), the implementer is given the opportunity to precompute data for use in the integration kernels. For example when using numerical quadrature rules to compute the double integral in the expression of the matrix entries, it is likely that a set of quadrature points for any given trial cells will be reused in interactions with a large number of test cells. To avoid computing these points and weights over and over, the client developer is given the opportunity to compute and store them by providing an appropriate method for \nquaddata\n . If memory use is more important the runtime, the client programmer is perfectly allowed to compute points and weights on the fly without storing them.\n\n\nfill!(zlocal, 0)\nstrat = quadrule(biop, tshapes, bshapes, p, tcell, q, bcell, qd)\nmomintegrals!(biop, tshapes, bshapes, tcell, bcell, zlocal, strat)\n\n\n\n\nFor a given pair \n(tcell,bcell)\n of test cell and trial cell (with respective indices \np\n and \nq\n in collections \ntest_elements\n and \nbsis_elements\n), all possible interactions between local shape functions are computed. After resetting the buffer used to store these interactions, the quadrature strategy is determined. The quadrature strategy in general could depend on:\n\n\n\n\nthe kernel \nbiop\n defining the integral operator,\n\n\nthe local test and trial shape functions \ntshapes\n and \nbshapes\n (functions of high polynomial degree and functions that are highly oscillatory typically require bespoke integration methods),\n\n\nand the geometric test and trial cells \ntcell\n and \nbcell\n (cells that touch or are near to each other lead to quickly varying or even singular integrands requiring dedicated integration rules).\n\n\n\n\nThe method returns an object \nstrat\n that: (i) describes (by its type and its data fields) the integration strategy that is appropriate to compute the current set of local interactions, (ii) contains all data precomputed and stored in \nqd\n that is relevant to this particular integration (for example a set of quadrature points and weights). This explains why the indices \np\n and \nq\n where passed too \nquadrule\n: they allow for the quick retrieval of relevant pre-stored data from \nqd\n.\n\n\nThe routing that is responsible for the actual computation of the interactions between the local shape functions takes the quadrule object \nstrat\n as one of its arguments. The idea is that \nmomintegrals!\n has many methods, not only for different types of kernel and shape functions, but also for different types of \nstrat\n. For example, there are implementations of \nmomintegrals!\n for the computation of the Maxwellian single layer operator w.r.t. spaces of Raviart-Thomas elements that employ double numerical quadrature, singularity extraction, and even more advanced integration routines.\n\n\nNote\n: the type of \nstrat\n depends on the orientation of the two interacting geometric cells. This information is only available at runtime. In other words, there will be a slight type instability at this point in the code. This is by design however, and not different from the use of virtual functions in an c++ implementation. Numerical experiments show that this form of runtime polymorphism results in negligible runtime overhead.\n\n\nWhen all possible interactions between local shape functions have been computed, they need to be stored in the global system matrix. This is done in the matrix assembly loop:\n\n\nfor j in 1 : num_bshapes\n    for i in 1 : num_tshapes\n        z = zlocal[i,j]\n        for (m,a) in tad[p,i]\n            for (n,b) in bad[q,j]\n                store(a*z*b, m, n)\n            end\n        end\n    end\nend\n\n\n\n\nFor both the test and trial local shape functions, the global indices at which they appear in the finite element space (and the corresponding weights) are retrieved from the assembly data objects. The contributing value \nv = a*z*b\n is constructed and its storage is delegated to the \nstore\n method, which we received as one of the arguments passed to \nassemble_chunk!\n. In the simplest case, \nassemble_chunk!\n can be used like this:\n\n\nZ = zeros(Complex128, numfunctions(tfs), numfunctions(bfs))\nstore(v, m, n) = (Z[m,n] += v)\nassemble_chunk!(kernel, tfs, bfs, store)\n\n\n\n\nIn other words \nstore\n will simply add the computed value to the specified entry in the global system matrix. Allowing the caller to specify \nstore\n as an argument allows for more flexibility than hardcoding this behaviour in the assembly routine. Indeed, when computing blocks of a larger system, or when e.g. the transposed or a multiple of a given operator is desired, a fairly simple redefinition of \nstore\n can provide this functionality. This is also the reason why \nassemble_chunk!\n ends in an exclamation mark: even though strictly speaking none of the arguments are modified, the function clearly has an effect on variables defined outside of its scope!\n\n\n\n\nCase Study: Implementation of the Nitsche Operator Assembly\n\n\nIn the Nitsche method for the Maxwell system, penalty terms are added to the classic discretisation of the EFIE. When discretized using a non-conforming finite elements space (typically because the underlying geometric mesh is not conforming), the penalty term will force the solution to be divergence conforming in some weak sense. The penalty term derives from the following bilinear form:\n\n\n\n\n\np(v,u) = \\int_{\\gamma} v(x) \\int_{\u0393} \\frac{e^{-ik|x-y|}}{4\u03c0|x-y|} u(y) dy dx\n\n\n\n\n\nNote that $u(x)$ is supported by a 2D surface $\u0393$ whereas $v(y)$ is supported by a 1D curve $\u03b3$. The complete implementation of this operator could look like\n\n\nmutable struct SingleLayerTrace{T} \n: MaxwellOperator3D\n    gamma::T\nend\n\nfunction quaddata(operator::SingleLayerTrace,\n    localtestbasis::LagrangeRefSpace,  localtrialbasis::LagrangeRefSpace,\n    testelements,  trialelements)\n\n  tqd = quadpoints(localtestbasis,  testelements,  (10,))\n  bqd = quadpoints(localtrialbasis, trialelements, (8,))\n\n  return QuadData(tqd, bqd)\nend\n\nfunction quadrule(op::SingleLayerTrace, g::LagrangeRefSpace, f::LagrangeRefSpace, i, \u03c4, j, \u03c3, qd)\n    DoubleQuadStrategy(\n        qd.tpoints[1,i],\n        qd.bpoints[1,j]\n    )\nend\n\nintegrand(op::SingleLayerTrace, kernel, g, \u03c4, f, \u03c3) = f[1]*g[1]*kernel.green\n\n\n\n\nEvery kernel corresponds with a type. Kernels can potentially depend on a set of parameters; these appear as fields in the type. Here our Nitsche kernel depends on the wavenumber. In quaddata we precompute quadrature points for all geometric cells in the supports of test and trial elements. This is fairly sloppy: only one rule for test and trial integration is considered. A high accuracy implementation would typically compute points for both low quality and high quality quadrature rules.\n\n\nAlso \nquadrule\n is sloppy: we always select a \nDoubleQuadStrategy\n to perform the computation of interactions between local shape functions. No singularity extraction or other advanced technique is considered for nearby interactions. Clearly amateurs at work here!\n\n\nBEAST\n provides a default implementation of an integration routine using double numerical quadrature. All that is required to tap into that implementation is a method overloading \nintegrand\n. From the above formula it is clear what this method should look like.\n\n\nThat's it!", 
            "title": "Assembly"
        }, 
        {
            "location": "/assemble/#the-matrix-assemble-routine", 
            "text": "A lot of the design of this package derives from the need to express boundary element and finite element matrix assembly in a concise but general manner that is compatible with a wide range of linear and bilinear forms as encountered in the solution of variational problems.  In this section the matrix assembly routine at the center of this package will be discussed. As a case study we will go over the steps required to extend support for new kernels and new finite element spaces.  The matrix assemble routine is surprisingly short:  function assemblechunk!(biop::IntegralOperator, tfs::Space, bfs::Space, store)\n\n    test_elements, tad = assemblydata(tfs)\n    bsis_elements, bad = assemblydata(bfs)\n\n    tshapes = refspace(tfs); num_tshapes = numfunctions(tshapes)\n    bshapes = refspace(bfs); num_bshapes = numfunctions(bshapes)\n\n    T = promote_type(scalartype(biop), scalartype(tfs), scalartype(bfs))\n    zlocal = zeros(T, num_tshapes, num_bshapes)\n\n    qd = quaddata(biop, tshapes, bshapes, test_elements, bsis_elements)\n    for (p,tcell) in enumerate(test_elements), (q,bcell) in enumerate(bsis_elements)\n\n        fill!(zlocal, 0)\n        strat = quadrule(biop, tshapes, bshapes, p, tcell, q, bcell, qd)\n        momintegrals!(biop, tshapes, bshapes, tcell, bcell, zlocal, strat)\n\n        for j in 1 : num_bshapes, i in 1 : num_tshapes\n            z = zlocal[i,j]\n            for (m,a) in tad[p,i], (n,b) in bad[q,j]\n                store(a*z*b, m, n)\nend end end end  Support for direct product spaces, linear combinations of kernels, non-standard storage of matrix elements, and parallel execution is provided by layers on top of this assembly routine. In this section we will focus on discussing the design and implementation of this inner building block that lies at the basis of more general functionality.  Finite element spaces are usually stored as a collection of functions that in turn each comprise contributions from a limited number of geometric elements that make up the support of the function. In FEM and BEM matrix assembly, however, we need the  tranposed  information: given a geometric cell, and a local shape function, we need the ability to efficiently retrieve the list of basis functions whose definition contains the given local shape function on the given cell and the weight (aka coefficient) by which it contributes. The data structure that contains this information is referred to as the assembly data  ad . In particular,  ad[e,s] , where  e  is the index of a geometric cell and  s  is the index of a local shape function, returns an iterable collection of pairs  (m,w)  where  m  is an index into the iterable collection of basis functions making up the finite element space and  w  is a weight, such that shape function  s  on geometric element  e  contributes with weight  w  to basis function  n .  test_elements, tad = assemblydata(tfs)\nbsis_elements, bad = assemblydata(bfs)  One final note on the  assemblydata  function: as you can see from the above snippet, the function returns, in addition to the actual assembly data, an iterable collection of geometric elements. This collection is a subset of the collection of elements making up the geometry on which the finite element space is defined. The elements returned are those that actually appear in the domain of one or more of the functions that span the finite element space. The double for loop that iterates over pairs of trial and testing functions will only visit those used elements. Elements that are part of the geometry but do not appear as part of the support of a function are skipped. This behaviour is required to guarantee scalability when using multiple threads in assembling the matrix: each thread is assigned a subset of the basis functions; visiting unused elements in all threads is harmful for the overall efficiency.  With this assembly data in hand, matrix assembly can be done by iterating over geometric cells, rather than over basis functions. Doing this avoids visiting a given geometric cell more than once. When computing matrices resulting from discretisation with e.g. Raviart-Thomas elements, this can speed up assembly time with a factor 9.  The problem of matrix assembly is now reduced to the computation of interactions between local shape functions defined on all possible pairs of geometric cells. The space of local shape functions can be retrieved by calling  tshapes = refspace(tfs); num_tshapes = numfunctions(tshapes)\nbshapes = refspace(bfs); num_bshapes = numfunctions(bshapes)  Here,  num_tshapes  and  num_bshapes  are the number of local shape functions. For example, when using Raviart-Thomas elements, the number of local shape functions equals three (one for every edge of the reference triangle).  Based on this dimension, and based on the types used to represent numbers in the fields over which the spaces and the kernel are defined, the storage for local shape function interaction is pre-allocated:  T = promote_type(scalartype(biop), scalartype(tfs), scalartype(bfs))\nzlocal = zeros(T, num_tshapes, num_bshapes)  Note that the computation of the storage type ensures that high precision or complex data types are only used when required. At all times the minimal storage type is selected. Not only does this keep memory use down, it also results in faster linear algebra computations such as matrix-vector multiplication.  Before entering the double for loop that is responsible for the enumeration of all pairs of geometric cells (a trial cell pairs with a test cell), the implementer is given the opportunity to precompute data for use in the integration kernels. For example when using numerical quadrature rules to compute the double integral in the expression of the matrix entries, it is likely that a set of quadrature points for any given trial cells will be reused in interactions with a large number of test cells. To avoid computing these points and weights over and over, the client developer is given the opportunity to compute and store them by providing an appropriate method for  quaddata  . If memory use is more important the runtime, the client programmer is perfectly allowed to compute points and weights on the fly without storing them.  fill!(zlocal, 0)\nstrat = quadrule(biop, tshapes, bshapes, p, tcell, q, bcell, qd)\nmomintegrals!(biop, tshapes, bshapes, tcell, bcell, zlocal, strat)  For a given pair  (tcell,bcell)  of test cell and trial cell (with respective indices  p  and  q  in collections  test_elements  and  bsis_elements ), all possible interactions between local shape functions are computed. After resetting the buffer used to store these interactions, the quadrature strategy is determined. The quadrature strategy in general could depend on:   the kernel  biop  defining the integral operator,  the local test and trial shape functions  tshapes  and  bshapes  (functions of high polynomial degree and functions that are highly oscillatory typically require bespoke integration methods),  and the geometric test and trial cells  tcell  and  bcell  (cells that touch or are near to each other lead to quickly varying or even singular integrands requiring dedicated integration rules).   The method returns an object  strat  that: (i) describes (by its type and its data fields) the integration strategy that is appropriate to compute the current set of local interactions, (ii) contains all data precomputed and stored in  qd  that is relevant to this particular integration (for example a set of quadrature points and weights). This explains why the indices  p  and  q  where passed too  quadrule : they allow for the quick retrieval of relevant pre-stored data from  qd .  The routing that is responsible for the actual computation of the interactions between the local shape functions takes the quadrule object  strat  as one of its arguments. The idea is that  momintegrals!  has many methods, not only for different types of kernel and shape functions, but also for different types of  strat . For example, there are implementations of  momintegrals!  for the computation of the Maxwellian single layer operator w.r.t. spaces of Raviart-Thomas elements that employ double numerical quadrature, singularity extraction, and even more advanced integration routines.  Note : the type of  strat  depends on the orientation of the two interacting geometric cells. This information is only available at runtime. In other words, there will be a slight type instability at this point in the code. This is by design however, and not different from the use of virtual functions in an c++ implementation. Numerical experiments show that this form of runtime polymorphism results in negligible runtime overhead.  When all possible interactions between local shape functions have been computed, they need to be stored in the global system matrix. This is done in the matrix assembly loop:  for j in 1 : num_bshapes\n    for i in 1 : num_tshapes\n        z = zlocal[i,j]\n        for (m,a) in tad[p,i]\n            for (n,b) in bad[q,j]\n                store(a*z*b, m, n)\n            end\n        end\n    end\nend  For both the test and trial local shape functions, the global indices at which they appear in the finite element space (and the corresponding weights) are retrieved from the assembly data objects. The contributing value  v = a*z*b  is constructed and its storage is delegated to the  store  method, which we received as one of the arguments passed to  assemble_chunk! . In the simplest case,  assemble_chunk!  can be used like this:  Z = zeros(Complex128, numfunctions(tfs), numfunctions(bfs))\nstore(v, m, n) = (Z[m,n] += v)\nassemble_chunk!(kernel, tfs, bfs, store)  In other words  store  will simply add the computed value to the specified entry in the global system matrix. Allowing the caller to specify  store  as an argument allows for more flexibility than hardcoding this behaviour in the assembly routine. Indeed, when computing blocks of a larger system, or when e.g. the transposed or a multiple of a given operator is desired, a fairly simple redefinition of  store  can provide this functionality. This is also the reason why  assemble_chunk!  ends in an exclamation mark: even though strictly speaking none of the arguments are modified, the function clearly has an effect on variables defined outside of its scope!", 
            "title": "The Matrix Assemble Routine"
        }, 
        {
            "location": "/assemble/#case-study-implementation-of-the-nitsche-operator-assembly", 
            "text": "In the Nitsche method for the Maxwell system, penalty terms are added to the classic discretisation of the EFIE. When discretized using a non-conforming finite elements space (typically because the underlying geometric mesh is not conforming), the penalty term will force the solution to be divergence conforming in some weak sense. The penalty term derives from the following bilinear form:   \np(v,u) = \\int_{\\gamma} v(x) \\int_{\u0393} \\frac{e^{-ik|x-y|}}{4\u03c0|x-y|} u(y) dy dx   Note that $u(x)$ is supported by a 2D surface $\u0393$ whereas $v(y)$ is supported by a 1D curve $\u03b3$. The complete implementation of this operator could look like  mutable struct SingleLayerTrace{T}  : MaxwellOperator3D\n    gamma::T\nend\n\nfunction quaddata(operator::SingleLayerTrace,\n    localtestbasis::LagrangeRefSpace,  localtrialbasis::LagrangeRefSpace,\n    testelements,  trialelements)\n\n  tqd = quadpoints(localtestbasis,  testelements,  (10,))\n  bqd = quadpoints(localtrialbasis, trialelements, (8,))\n\n  return QuadData(tqd, bqd)\nend\n\nfunction quadrule(op::SingleLayerTrace, g::LagrangeRefSpace, f::LagrangeRefSpace, i, \u03c4, j, \u03c3, qd)\n    DoubleQuadStrategy(\n        qd.tpoints[1,i],\n        qd.bpoints[1,j]\n    )\nend\n\nintegrand(op::SingleLayerTrace, kernel, g, \u03c4, f, \u03c3) = f[1]*g[1]*kernel.green  Every kernel corresponds with a type. Kernels can potentially depend on a set of parameters; these appear as fields in the type. Here our Nitsche kernel depends on the wavenumber. In quaddata we precompute quadrature points for all geometric cells in the supports of test and trial elements. This is fairly sloppy: only one rule for test and trial integration is considered. A high accuracy implementation would typically compute points for both low quality and high quality quadrature rules.  Also  quadrule  is sloppy: we always select a  DoubleQuadStrategy  to perform the computation of interactions between local shape functions. No singularity extraction or other advanced technique is considered for nearby interactions. Clearly amateurs at work here!  BEAST  provides a default implementation of an integration routine using double numerical quadrature. All that is required to tap into that implementation is a method overloading  integrand . From the above formula it is clear what this method should look like.  That's it!", 
            "title": "Case Study: Implementation of the Nitsche Operator Assembly"
        }
    ]
}